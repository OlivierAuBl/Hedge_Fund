from binance.client import Client
import pandas as pd
import matplotlib.pyplot as pt
import time  # use to manage the API limit of 1200 requests by min
import numpy as np

class BuildDatabase:

    def __init__(self, api_key, api_secret, symbol):
        self.client = Client(api_key, api_secret)
        self.symbol = symbol
        self.database = pd.DataFrame(columns=['id', 'isBestMatch', 'isBuyerMaker', 'price', 'qty', 'time'])

    def start_data_extract(self, nrows):
        """
        Function used to create the raw database from the API
        :param nrows: int
            Number of rows requested in the database. It needs to be a multiple of 500.
        :return:
            return the database extracted from the API
        """
        # Get the ID now
        last_id = self.client.get_recent_trades(symbol=self.symbol, limit=1)[0]['id']
        start_id = last_id - nrows + 1

        # TODO: add condition not to scrape more than the API limit !!!!!!! (1200 to check)
        if (nrows % 500 == 0) : #or (nrows < 1200 * 500)
            print("Data requested to the API from Id = {} to Id = {}".format(start_id, last_id))
        else:
            raise AttributeError('Fuck you, you have to put a multiple of 500 for nrows, '
                                 'or requested more than 1200$500 rows, read the doc next time.')

        for i in range(start_id, last_id, 500):  # 500 is max limit
            extract_i = self.client.get_historical_trades(symbol=self.symbol, limit=500, fromId=i)
            self.database = pd.concat([self.database, pd.DataFrame(extract_i)])
            time.sleep(2)  # theoretically a .5s pause should be enough but with a small margin that will be enough

        return self.database

    def create_modeling_database(self):

        # Changing the awful time display into a date
        self.database["date"] = pd.to_datetime(self.database['time'], unit='ms')
        # todo: aggregate each 10 seconds and build new features !
        return



# TODO choisir des monnaies à trader :
#forex = np.array(["BNBBTC","LTCBTC","ETHBTC","NEOBTC"]) # looks like les plus liquides... pas sur du neo
symbol="BNBBTC"

#for symbol in forex
c = BuildDatabase(api_key, api_secret, symbol)
db = c.start_data_extract(200000) # 20000 seems a bit low... 5h history

db["date"] = pd.to_datetime(db['time'], unit='ms')
db.index = db["date"]
db = db.drop(["date", "time", "id"], axis=1)

db = db.apply(pd.to_numeric)  # todo: put float 32 + comment
db.to_csv(path_or_buf=symbol + "_extract.csv", index=False)


    # create not bool columns
    db = db.rename(columns={'isBestMatch': 'isBestMatch_T', 'isBuyerMaker': 'isBuyerMaker_T'})
    db['isBestMatch_F'] = not (db['isBestMatch_T']).all()
    db['isBuyerMaker_F'] = not (db['isBuyerMaker_T']).all()

    # Create new columns
    # Real exchanged quantity: price_x_qty
    db['value_exchanged'] = db['price'] * db['qty']
    # Quanty sold / bought
    db["qty_sold"] = db['qty'] * db['isBuyerMaker_T']
    db["qty_bought"] = db['qty'] * db['isBuyerMaker_F']
    # Value sold / bought
    db['value_sold'] = db['value_exchanged'] * db['isBuyerMaker_T']
    db['value_bought'] = db['value_exchanged'] * db['isBuyerMaker_F']
    # Price variation / second derivative
    db['price_variation'] = db["price"].diff()
    db['price_variation_diff'] = db["price"].diff().diff()

    # Threshold;
    thr_price_variation = db['price_variation'].quantile(0.9)
    db['price_variation_thr'] = db['price_variation'] > thr_price_variation

    # aggregation columns:
    t_agg = '2s'
    agg_db = db.resample(t_agg).sum()

    for col in db.columns:

        if db[col].dtypes != 'bool':
            agg_db[col + '_max'] = db[col].resample(t_agg).max()
            agg_db[col + '_min'] = db[col].resample(t_agg).min()
            agg_db[col + '_mean'] = db[col].resample(t_agg).mean()

    # Trend last x minutes
    var = 'price_variation'
    for t in [3, 5, 8]:
        t = 3
        len_time = '{}T'.format(t)  # T for minutes
        mini_db_agg = pd.DataFrame(db[var].resample(len_time).sum())
        mini_db_agg.rename(columns={var: '{}_trend_{}'.format(var, len_time)}, inplace=True)
        mini_db_agg = mini_db_agg.resample(t_agg).max()
        mini_db_agg = mini_db_agg.interpolate(method='zero')
        agg_db = pd.merge(agg_db, mini_db_agg, how='left', left_index=True, right_index=True)

    agg_db["weekday_name"] = agg_db.index
    agg_db["weekday_name"] = agg_db["weekday_name"].dt.weekday_name
# todo : reflechir aux NaN à la fin.
# todo : reflechir a des variables type matin/soir etc...
